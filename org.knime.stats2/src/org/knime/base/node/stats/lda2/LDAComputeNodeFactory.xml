<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE knimeNode PUBLIC "-//UNIKN//DTD KNIME Node 2.0//EN" "http://www.knime.org/Node.dtd">
<knimeNode icon="./lda_compute-icon.png" type="Manipulator">
    <name>Linear Discriminant Analysis Compute</name>
    
    <shortDescription>
        Linear discriminant analysis computation.
    </shortDescription>
    
    <fullDescription>
        <intro>
            <a href="http://en.wikipedia.org/wiki/Linear_discriminant_analysis">Linear Discriminant Analysis (LDA)</a> is similar to the <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Compnent Analysis (PCA)</a> but tries to take class information into account to achieve a dimensionality reduction while keeping the class separation high. The result may be used in a subsequent classification. The method tries to maximize the ratio of inter-class to intra-class scatter in order to achieve a projection where data points of the same class are close to each other, but far from data points of other classes.
        </intro>

        <option name="Class column">The column containing class information</option>
        <option name="Column selection">The columns of the original dimensions</option>
    </fullDescription>
    
    <ports>
        <inPort index="0" name="Input data">Input data for the LDA</inPort>
        <outPort index="0" name="Spectral decomposition">Table containing parameters extracted from the LDA. Each row in the table represents one of the discriminant functions, whereby the rows are sorted with decreasing eigenvalues. The first column in the table contains the component's eigenvalue, indicating how well the function differentiates the groups.
Each subsequent column (labeled with the name of the selected input column) contains a coefficient representing the influence of the respective input dimension to the reduced dimension. The higher the absolute value, the higher the influence of the input dimension on the reduced dimension. 
In other words, let the eigenvalue column aside and choose the numbers of dimensions to reduce to from the top, this is the transformation matrix.
The mapping of the input rows to, e.g. the first principal axis, is computed as follows (all done in the "Linear Discriminant Analysis apply" node): For each dimension in the original space subtract the dimension's mean value and then multiply the resulting vector with the vector given by this table.</outPort>
        <outPort index="1" name="LDA model">Model with projection to the reduced space, used in the "Linear Discriminant Analysis Apply" node to apply the transformation to, e.g. another validation set.</outPort>
        
    </ports>    
</knimeNode>
